<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>VoiceCal</title>
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="icon" href="/icon.png">
<link rel="apple-touch-icon" href="/icon.png">

<style>
body {
  font-family: Arial, sans-serif;
  background: #f4f6f9;
  color: #000;
  text-align: center;
  padding: 30px;
}
.container { max-width: 500px; margin: auto; }
.mic-button {
  width: 120px;
  height: 120px;
  margin: 25px auto;
  border-radius: 50%;
  background: #ffffff;
  box-shadow: 0 6px 18px rgba(0,0,0,0.15);
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
.mic-button img { width: 70%; }
.recording { background: #ff4d4d !important; }
.card {
  background: #ffffff;
  padding: 15px;
  margin-top: 15px;
  border-radius: 12px;
  text-align: left;
}
#status { margin-top: 20px; font-weight: bold; }
</style>

<script src="https://accounts.google.com/gsi/client" async defer></script>
<script src="https://apis.google.com/js/api.js"></script>
</head>

<body>

<div class="container">
  <h1>VoiceCal</h1>
  <p>Version 5.9</p>

  <div class="mic-button" id="micBtn" onclick="startListening()">
    <img src="icon.png" alt="Speak">
  </div>

  <div class="card" id="transcriptCard" style="display:none;">
    <strong>You said:</strong>
    <div id="transcript"></div>
  </div>

  <div id="status">Ready.</div>
</div>

<script>

const CLIENT_ID = "YOUR_REAL_CLIENT_ID";
const API_KEY = "AIzaSyBmvb2xvKm0zagn20ZGYTE4nwQbHob-bso";
const SCOPES = "630726897821-4m33kk0js2fefdn102j6mumc1cooih49.apps.googleusercontent.com";

let tokenClient;
let pendingEvent = null;
let recognition;
let finalTranscript = "";
let awaitingMealTime = false;
let storedMealText = "";

/* ================= GOOGLE INIT ================= */

function initGapi() {
  gapi.load("client", async () => {
    await gapi.client.init({
      apiKey: API_KEY,
      discoveryDocs: ["https://www.googleapis.com/discovery/v1/apis/calendar/v3/rest"],
    });
  });
}

function initGIS() {
  function wait() {
    if (!window.google || !google.accounts || !google.accounts.oauth2) {
      setTimeout(wait, 100);
      return;
    }
    tokenClient = google.accounts.oauth2.initTokenClient({
      client_id: CLIENT_ID,
      scope: SCOPES,
      callback: handleTokenResponse,
    });
  }
  wait();
}

async function handleTokenResponse(resp) {
  if (resp.error) {
    setStatus("Authentication failed.");
    return;
  }

  gapi.client.setToken({ access_token: resp.access_token });

  try {
    setStatus("Creating event...");
    await gapi.client.calendar.events.insert({
      calendarId: "primary",
      resource: pendingEvent
    });
    setStatus("âœ… Event created!");
    speak("Event created.");
  } catch (err) {
    setStatus("Failed to create event.");
  }
}

/* ================= VOICE ================= */

function startListening() {

  const mic = document.getElementById("micBtn");

  if (!('webkitSpeechRecognition' in window)) {
    alert("Speech recognition not supported.");
    return;
  }

  finalTranscript = "";
  recognition = new webkitSpeechRecognition();
  recognition.lang = 'en-US';
  recognition.continuous = true;
  recognition.interimResults = true;

  let silenceTimer;

  mic.classList.add("recording");
  setStatus("Listening...");
  recognition.start();

  recognition.onresult = function(event) {
    clearTimeout(silenceTimer);

    let transcript = "";
    for (let i = event.resultIndex; i < event.results.length; i++) {
      transcript += event.results[i][0].transcript;
    }

    finalTranscript = transcript;

    silenceTimer = setTimeout(() => {
      recognition.stop();
    }, 2000);
  };

  recognition.onend = function() {

    mic.classList.remove("recording");

    if (!finalTranscript.trim()) {
      setStatus("No speech detected.");
      return;
    }

    document.getElementById("transcript").innerText = finalTranscript;
    document.getElementById("transcriptCard").style.display = "block";

    const lower = finalTranscript.toLowerCase().trim();

    // If waiting for meal time
    if (awaitingMealTime) {
      awaitingMealTime = false;
      createMealEvent(storedMealText, lower);
      return;
    }

    // Detect meal triggers
    if (
      lower.startsWith("breakfast") ||
      lower.startsWith("lunch") ||
      lower.startsWith("dinner") ||
      lower.startsWith("snack")
    ) {

      const timeRegex = /(\d{1,2})(?::(\d{2}))?\s*(a\.?m\.?|p\.?m\.?)/i;

      if (!timeRegex.test(lower)) {
        storedMealText = finalTranscript.trim();
        awaitingMealTime = true;
        speak("What time?");
        setStatus("Waiting for time...");
        startListening();
        return;
      }
    }

    parseText(finalTranscript.trim(), finalTranscript.trim());
  };
}

/* ================= PARSER ================= */

function createMealEvent(mealText, timeText) {

  const mealType = mealText.split(" ")[0].toUpperCase();
  const description = mealText.substring(mealType.length).trim();
  const cleanTitle = mealType + ": " + description;

  parseText(cleanTitle, timeText);
}

function parseText(titleText, timeSource) {

  let date = new Date();
  const lower = (timeSource || titleText).toLowerCase();

  if (lower.includes("tomorrow")) {
    date.setDate(date.getDate() + 1);
  }

  const timeRegex = /(\d{1,2})(?::(\d{2}))?\s*(a\.?m\.?|p\.?m\.?)/i;
  const match = lower.match(timeRegex);

  if (match) {
    let hour = parseInt(match[1]);
    let minute = match[2] ? parseInt(match[2]) : 0;
    let period = match[3].toLowerCase();

    if (period.includes("p") && hour !== 12) hour += 12;
    if (period.includes("a") && hour === 12) hour = 0;

    date.setHours(hour, minute, 0, 0); // prevents shifting
  }

  const end = new Date(date.getTime() + 60 * 60 * 1000);

  pendingEvent = {
    summary: titleText,
    start: { dateTime: date.toISOString() },
    end: { dateTime: end.toISOString() },
    reminders: {
      useDefault: false,
      overrides: [{ method: "popup", minutes: 30 }]
    }
  };

  setStatus("Authenticating...");
  tokenClient.requestAccessToken({
    prompt: gapi.client.getToken() ? "" : "consent"
  });
}

function setStatus(msg) {
  document.getElementById("status").innerText = msg;
}

function speak(text) {
  speechSynthesis.speak(new SpeechSynthesisUtterance(text));
}

initGapi();
initGIS();

</script>

</body>
</html>

